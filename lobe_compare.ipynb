{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\pll\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_tools.m_dataset import MDataset,ch_names \n",
    "from torch_tools.train_test import train,test\n",
    "from torch_tools.DOCinformer import DOCinformer\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import gc\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_window = 10\n",
    "t_overlap = 0.0\n",
    "sf = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "valid_ratio = 0.2\n",
    "random_state = 555\n",
    "ckp_parent_dir = 'ckp//pdoc//DOCinformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取pdoc\n",
    "sub_regex = 'F:\\\\PLL\\\\静息态数据没有ICA\\\\*.mat'\n",
    "sub_paths = glob(sub_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_kfold_withvalid(sub_dataset_list,n_folds,valid_ratio,random_state=0):\n",
    "    # 分k折\n",
    "    train_folds={}\n",
    "    valid_folds={}\n",
    "    test_folds={}\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    for i, (train_indexes, test_indexes) in enumerate(kf.split(sub_dataset_list)):\n",
    "        train_subjects = [sub_dataset_list[train_index]  for train_index in train_indexes]\n",
    "        test_subjects = [sub_dataset_list[test_index]  for test_index in test_indexes]\n",
    "        # valid\n",
    "        if valid_ratio == 0:\n",
    "            valid_subjects = test_subjects\n",
    "        else:\n",
    "            train_subjects,valid_subjects = train_test_split(train_subjects,test_size=valid_ratio,shuffle=True,random_state=random_state)\n",
    "        # 记录本fold的subject编号\n",
    "        train_folds[i]=train_subjects\n",
    "        valid_folds[i]=valid_subjects\n",
    "        test_folds[i]=test_subjects   \n",
    "    return train_folds,valid_folds,test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_tools.train_test import test_roc\n",
    "def testnfold(standard_chs,nets,ckp_dir):\n",
    "    # load dataset\n",
    "    pdoc_sub_dataset_list = []\n",
    "    pdoc_label_dict =  {\n",
    "        'VS':0,\n",
    "        'MCS':1,\n",
    "        # 'MCS-':1,\n",
    "        # 'MCS+':1,\n",
    "    } \n",
    "    for sub_path in sub_paths:\n",
    "        sub_dataset = MDataset(sub_path,t_window,t_overlap,standard_chs,pdoc_label_dict)\n",
    "        if len(sub_dataset)>0:\n",
    "            pdoc_sub_dataset_list.append(sub_dataset)\n",
    "    pdoc_train_folds,pdoc_valid_folds,pdoc_test_folds  = sub_kfold_withvalid(pdoc_sub_dataset_list,n_folds,valid_ratio,random_state)\n",
    "    \n",
    "    avg_test_acc = 0.0\n",
    "    avg_test_precision = 0.0\n",
    "    avg_test_f1 = 0.0\n",
    "    avg_test_recall = 0.0\n",
    "    avg_test_auc = 0.0\n",
    "    fold_test_results = []\n",
    "    for i in range(n_folds):\n",
    "        fold_ckp_path = ckp_dir+'\\\\'+f'fold_{i}.pth'\n",
    "        net = nets[i]\n",
    "        test_subs = pdoc_test_folds[i]\n",
    "        fold_test_result = test(net,fold_ckp_path,DataLoader(ConcatDataset(test_subs),batch_size=32,shuffle=True,drop_last=False),False)\n",
    "        # 记录本折测试结果\n",
    "        avg_test_acc += fold_test_result[\"acc\"]\n",
    "        avg_test_precision += fold_test_result[\"precision\"]\n",
    "        avg_test_recall += fold_test_result[\"recall\"]\n",
    "        avg_test_f1 += fold_test_result[\"f1\"]\n",
    "        # 记录本折ROC结果\n",
    "        mean_fpr,interp_tpr,roc_auc = test_roc(net,fold_ckp_path,DataLoader(ConcatDataset(test_subs),batch_size=32,shuffle=True,drop_last=False))\n",
    "        avg_test_auc += roc_auc\n",
    "        fold_test_result[\"auc\"] = roc_auc\n",
    "        fold_test_results.append(fold_test_result)\n",
    "\n",
    "        \n",
    "    \n",
    "    # 最后一行是平均\n",
    "    avg_test_acc = avg_test_acc/n_folds\n",
    "    avg_test_precision = avg_test_precision/n_folds\n",
    "    avg_test_recall = avg_test_recall/n_folds\n",
    "    avg_test_f1 = avg_test_f1/n_folds\n",
    "    avg_test_auc = avg_test_auc/n_folds\n",
    "    avg_result = {\"precision\":avg_test_precision,\"recall\":avg_test_recall,\"f1\":avg_test_f1,\"acc\":avg_test_acc,\"auc\":avg_test_auc}\n",
    "    print(avg_result)   \n",
    "    return avg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(trial,standard_chs,part_chs = None):\n",
    "    ckp_dir = ckp_parent_dir + '\\\\' + f'ch{len(standard_chs)}-trail{trial.number}'\n",
    "    # 模型结构参数\n",
    "    pool_time_stride = trial.suggest_categorical(\"pool_time_stride\", [200])\n",
    "    n_filters_time = trial.suggest_categorical(\"n_filters_time\", [64])\n",
    "    filter_time_length = trial.suggest_categorical(\"filter_time_length\", [25])\n",
    "    depth = trial.suggest_int('depth', 1,1)\n",
    "    att_heads =  trial.suggest_int('att_heads', 1,1)\n",
    "    # 训练参数\n",
    "    epochs = 4\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16])\n",
    "    lr = (3**trial.suggest_int('lr',1,1))*1e-4\n",
    "    wd = trial.suggest_categorical(\"wd\", [0.1])\n",
    "   # setting\n",
    "    nets = [DOCinformer(n_outputs=2, input_window_seconds=t_window,sfreq=sf, standard_chs = standard_chs,positionEncoding = 'coordinate',channel_drop_prob = 0.2,att_drop_prob = 0.25,\n",
    "                                              filter_time_length=filter_time_length,att_depth=depth,att_heads=att_heads,n_filters_time=n_filters_time,pool_time_stride = pool_time_stride,pool_time_length=pool_time_stride)\n",
    "            for i in range(n_folds)]\n",
    "    optimizers = [torch.optim.AdamW(net.parameters(), lr=lr,weight_decay=lr*wd)\n",
    "            for net in nets]\n",
    "    # t\n",
    "    \n",
    "    for net in nets:\n",
    "        net.select_channel(part_chs)\n",
    "    return testnfold(part_chs,nets,ckp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = joblib.load(ckp_parent_dir+\"//best_trail.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.7950405765864472, 'recall': 0.895813049856877, 'f1': 0.838874785967129, 'acc': 0.7746225619358532, 'auc': 0.7560074289283094}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7950405765864472,\n",
       " 'recall': 0.895813049856877,\n",
       " 'f1': 0.838874785967129,\n",
       " 'acc': 0.7746225619358532,\n",
       " 'auc': 0.7560074289283094}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_chs = ['Fpz','P8', 'Oz', 'TP9', 'C4', 'FC6', 'F4', 'CP6', 'CP1', 'P4',  \n",
    "           'T7', 'FC1', 'O1', 'TP10', 'FC2', 'CP2', 'C3', 'P7', 'FC5', 'F7', \n",
    "           'P3', 'Fp2', 'O2', 'F8', 'Pz', 'CP5', 'F3', 'Fp1', 'T8','Fz']\n",
    "result(best_trial,standard_chs,standard_chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobe_group = {\n",
    "    'Fp' : ['Fp1', 'Fp2','Fpz'],\n",
    "    'F' : ['Fz','F7', 'F8', 'F3', 'F4'],\n",
    "    'FC': ['FC5', 'FC6', 'FC1', 'FC2'],\n",
    "    'C': ['CP5', 'CP6', 'CP1', 'CP2','C3', 'C4'],\n",
    "    'P': ['P7', 'P8', 'P3', 'P4', 'Pz'],\n",
    "    'O': ['O1', 'O2', 'Oz'],\n",
    "    'T': ['T7', 'T8', 'TP9', 'TP10']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove lobe:Fp\n",
      "{'precision': 0.683562204538702, 'recall': 0.9800601493515286, 'f1': 0.8011484449330016, 'acc': 0.6800450345491514, 'auc': 0.6216516028386624}\n",
      "\n",
      "remove lobe:F\n",
      "{'precision': 0.7967619041995913, 'recall': 0.8681558264086144, 'f1': 0.8274414055749049, 'acc': 0.762530352650384, 'auc': 0.7531449935399319}\n",
      "\n",
      "remove lobe:FC\n",
      "{'precision': 0.7958536197954473, 'recall': 0.8826185212752087, 'f1': 0.8335636965808222, 'acc': 0.7688477588465721, 'auc': 0.7522546138255825}\n",
      "\n",
      "remove lobe:C\n",
      "{'precision': 0.7945917395443516, 'recall': 0.90748899981834, 'f1': 0.8436797912071574, 'acc': 0.7799016894830976, 'auc': 0.7550803603301317}\n",
      "\n",
      "remove lobe:P\n",
      "{'precision': 0.7899729800920433, 'recall': 0.9086154530209172, 'f1': 0.8414757369157538, 'acc': 0.7761770001707797, 'auc': 0.7586790847503762}\n",
      "\n",
      "remove lobe:O\n",
      "{'precision': 0.795154076200936, 'recall': 0.9041163572002432, 'f1': 0.8429565874264047, 'acc': 0.780025561599105, 'auc': 0.7587357507290353}\n",
      "\n",
      "remove lobe:T\n",
      "{'precision': 0.797743924171362, 'recall': 0.8955267629031898, 'f1': 0.8403482325714287, 'acc': 0.7770221444804843, 'auc': 0.7632232177786331}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lobe_remove_result = {}\n",
    "for lobe_name in lobe_group:\n",
    "    print(f\"remove lobe:{lobe_name}\")\n",
    "    lobe_chs =  lobe_group[lobe_name]\n",
    "    other_chs = [item for item in standard_chs if item not in lobe_chs]\n",
    "    result_dict = result(best_trial,standard_chs,other_chs)\n",
    "    result_dict['channels'] = len(other_chs)\n",
    "    lobe_remove_result[lobe_name] = result_dict\n",
    "    print(\"\")\n",
    "lobe_remove_df = pd.DataFrame.from_dict(lobe_remove_result, orient='index')\n",
    "lobe_remove_df.to_csv('lobe_remove_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
